{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alchemy_pruning.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hEJ6J1QBQsXU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bayes-by-Backprop and Pruning with Alchemy, TensorFlow (and Sonnet)"
      ]
    },
    {
      "metadata": {
        "id": "sWu1AO3RGbEc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "986dca9b-58dc-4f12-bea7-d8269f93deb3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524669768456,
          "user_tz": 240,
          "elapsed": 10753,
          "user": {
            "displayName": "Sam Wenke",
            "photoUrl": "//lh6.googleusercontent.com/-f8Ky_WO2HTs/AAAAAAAAAAI/AAAAAAAAAG8/Q5eXh5dH1rg/s50-c-k-no/photo.jpg",
            "userId": "108962687437084869445"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone -b experimental https://git@github.com/wenkesj/alchemy.git ~/alchemy\n",
        "!(cd ~/alchemy; pip install -q .)\n",
        "!pip install -q dm-sonnet observations tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/alchemy'...\n",
            "remote: Counting objects: 274, done.\u001b[K\n",
            "remote: Compressing objects: 100% (183/183), done.\u001b[K\n",
            "remote: Total 274 (delta 143), reused 219 (delta 88), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (274/274), 62.63 KiB | 8.95 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6g0VEgK2B589",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bayes by Backprop is an algorithm for learning a distribution\n",
        "over neural network weights."
      ]
    },
    {
      "metadata": {
        "id": "zLcisYumA8z7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import alchemy as ay\n",
        "import tensorflow as tf; tf.set_random_seed(1)\n",
        "import sonnet.python.custom_getters.bayes_by_backprop as bbb\n",
        "\n",
        "prior_builder, posterior_builder = ay.utils.custom_scale_mixture_prior_factory(\n",
        "    pi=.01, sigma1=.25, sigma2=.01)\n",
        "\n",
        "sampling_mode_ph = tf.placeholder(tf.string, [])\n",
        "\n",
        "get_bbb_variable_fn = bbb.bayes_by_backprop_getter(\n",
        "    posterior_builder=posterior_builder,\n",
        "    prior_builder=prior_builder,\n",
        "    kl_builder=bbb.stochastic_kl_builder,\n",
        "    sampling_mode_tensor=sampling_mode_ph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xavf0q11D0KW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining the Problem\n",
        "This uses the **MNIST** dataset."
      ]
    },
    {
      "metadata": {
        "id": "WxNwXBHjDytS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from observations import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist('data')\n",
        "train_size, test_size = len(x_train), len(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9YZqGM5YUZLe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining the Model"
      ]
    },
    {
      "metadata": {
        "id": "pKdxttcjGqiu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs_ph = tf.placeholder(tf.float32, [None, 784])\n",
        "labels_ph = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "def model_fn(inputs_ph):\n",
        "  inputs = tf.reshape(inputs_ph, [tf.shape(inputs_ph)[0], 28, 28, 1])\n",
        "  y = tf.layers.conv2d(tf.cast(inputs, tf.float32) / 127, 32, (3, 3), \n",
        "                       activation=tf.nn.relu)\n",
        "  y = tf.layers.conv2d(y, 64, (3, 3), activation=tf.nn.relu)\n",
        "  y = tf.contrib.layers.flatten(y)\n",
        "  y = tf.layers.dense(\n",
        "      y, units=128,\n",
        "      activation=tf.nn.relu)\n",
        "  y = tf.layers.dense(\n",
        "      y, units=10)\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WcoUjGHXCGhh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create the training network using the getter"
      ]
    },
    {
      "metadata": {
        "id": "E9fr93XjCAp0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "bbb_scope = 'bbb'\n",
        "with tf.variable_scope(bbb_scope, custom_getter=get_bbb_variable_fn) as vs:\n",
        "  bbb_logits = model_fn(inputs_ph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MiWEg3emCKFN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create the pruning op"
      ]
    },
    {
      "metadata": {
        "id": "r_jYhsr_AwVl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "metadata = bbb.get_variable_metadata()\n",
        "total_variables = sum([ay.utils.product(meta.raw_variable_shape) \n",
        "                       for meta in metadata])\n",
        "percentage_ph = tf.placeholder(tf.float32, [])\n",
        "pruned_vars_op = ay.contrib.train.prune_by_bbb(metadata, percentage_ph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oZa8ASRCDO6J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Minimize the total loss"
      ]
    },
    {
      "metadata": {
        "id": "nA48fu7pDM0Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(bbb_scope):\n",
        "  loss_op = tf.reduce_mean(\n",
        "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          labels=labels_ph, logits=bbb_logits, name='loss'),\n",
        "      axis=-1)\n",
        "\n",
        "  loss_op += bbb.get_total_kl_cost() / train_size\n",
        "  train_op = tf.train.AdamOptimizer(1e-3).minimize(loss_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCdcFpHIEqbA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`bbb` validation criterion"
      ]
    },
    {
      "metadata": {
        "id": "sUS1aKNSEpIV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "bbb_pred_op = tf.cast(tf.argmax(bbb_logits, axis=-1), tf.int32)\n",
        "bbb_accy_op = tf.reduce_mean(\n",
        "    tf.cast(tf.equal(bbb_pred_op, labels_ph), tf.float32), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "as67gtksCOGS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create the pruned network template"
      ]
    },
    {
      "metadata": {
        "id": "rjYL40H8CSvn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "template_scope = 'template'\n",
        "with tf.variable_scope(template_scope) as vs:\n",
        "  template_logits = model_fn(inputs_ph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XFiaF_eGFYN1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`template` validation criterion"
      ]
    },
    {
      "metadata": {
        "id": "aG0tkC8fE9xn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "template_pred_op = tf.cast(tf.argmax(template_logits, axis=-1), tf.int32)\n",
        "template_accy_op = tf.reduce_mean(\n",
        "    tf.cast(tf.equal(template_pred_op, labels_ph), tf.float32), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UhE9zhg1Ccon",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Retrieve the variables so we can prune them in-place. In other words, find the variables from `'bbb'` that correspond to `'template'`"
      ]
    },
    {
      "metadata": {
        "id": "_CWoRO_RCh0a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "template_variables = tf.trainable_variables(scope=template_scope)\n",
        "assign_pruned_vars_op = ay.contrib.train.assign_pruned_by_bbb_to_template(\n",
        "    metadata, pruned_vars_op, template_variables,\n",
        "    from_scope=bbb_scope, to_scope=template_scope)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ha4OEtY7Mvlw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Another (viable) inspiration of using BBB is the ability to use a pre-trained model and then prune it, getting similar results. \n",
        "\n",
        "This can be accomplished with very little work by using the fact that the pruned model's weights are sampled from the **mean** of the distributions. With this assumption, you can take the pre-trained weights and set those as the **mean**s of the BBB model and (only or maybe not, need to write a paper on the results **¯\\_(ツ)_/¯**) train the **variance** to get the **SNR**."
      ]
    },
    {
      "metadata": {
        "id": "GpVhhyX0MutN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# using a pre-trained model, and comment below this\n",
        "# assign_template_vars_op = ay.contrib.train.assign_template_to_prune_by_bbb(\n",
        "#     template_variables, metadata,\n",
        "#     from_scope=template_scope, to_scope=bbb_scope)\n",
        "\n",
        "with tf.variable_scope(template_scope):\n",
        "  template_loss_op = tf.reduce_mean(\n",
        "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          labels=labels_ph, logits=template_logits, name='loss'),\n",
        "      axis=-1)\n",
        "  # using a pre-trained model, and comment below this\n",
        "  # template_train_op = tf.train.AdamOptimizer(1e-3).minimize(template_loss_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ouBkGplJolU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Baseline Training and Validation"
      ]
    },
    {
      "metadata": {
        "id": "77WVlIukMx5P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be83c2bf-f66f-4676-c541-966d4495545d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524669850225,
          "user_tz": 240,
          "elapsed": 60430,
          "user": {
            "displayName": "Sam Wenke",
            "photoUrl": "//lh6.googleusercontent.com/-f8Ky_WO2HTs/AAAAAAAAAAI/AAAAAAAAAG8/Q5eXh5dH1rg/s50-c-k-no/photo.jpg",
            "userId": "108962687437084869445"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from tqdm import trange\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs = 1\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss = 0.\n",
        "  train_set = ay.utils.generate_dataset((x_train, y_train), batch_size)\n",
        "  train_msg = 'Epoch {} mean train loss = {:.4f}'\n",
        "  train_range = trange(\n",
        "      train_size // batch_size, \n",
        "      desc=train_msg.format(epoch, train_loss),\n",
        "      file=sys.stdout)\n",
        "  for _ in train_range:\n",
        "    x, y = next(train_set)\n",
        "    # using a pre-trained model, and comment below this\n",
        "    # train_loss, _ = sess.run((template_loss_op, template_train_op), feed_dict={\n",
        "    #     inputs_ph: x,\n",
        "    #     labels_ph: y,\n",
        "    # })\n",
        "    train_loss, _ = sess.run((loss_op, train_op), feed_dict={\n",
        "        inputs_ph: x,\n",
        "        labels_ph: y, \n",
        "        sampling_mode_ph: bbb.EstimatorModes.sample,\n",
        "    })\n",
        "    train_range.set_description(train_msg.format(epoch, train_loss))\n",
        "\n",
        "  test_accy = 0.\n",
        "  test_set = ay.utils.generate_dataset((x_test, y_test), batch_size)\n",
        "  for test_steps_taken in range(test_size // batch_size):\n",
        "    x, y = next(test_set)\n",
        "    # using a pre-trained model, and comment below this\n",
        "    # test_accy += sess.run(template_accy_op, feed_dict={\n",
        "    #     inputs_ph: x,\n",
        "    #     labels_ph: y,\n",
        "    # })\n",
        "    test_accy += sess.run(bbb_accy_op, feed_dict={\n",
        "        inputs_ph: x,\n",
        "        labels_ph: y,\n",
        "        sampling_mode_ph: bbb.EstimatorModes.mean,\n",
        "    })\n",
        "  print('Accy {:.2f}%'.format(100. * (test_accy / (test_steps_taken + 1))))\n",
        "\n",
        "# using a pre-trained model, uncomment this\n",
        "# sess.run(assign_template_vars_op)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 mean train loss = 19.7494: 100%|██████████| 937/937 [00:57<00:00, 16.34it/s]\n",
            "Accy 89.22%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UN231BoeJhVZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prune and validate"
      ]
    },
    {
      "metadata": {
        "id": "hAcxl11PFnC1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1513
        },
        "outputId": "2f1655d1-560f-44a8-98ee-1c0b47d85f7a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524669862144,
          "user_tz": 240,
          "elapsed": 11870,
          "user": {
            "displayName": "Sam Wenke",
            "photoUrl": "//lh6.googleusercontent.com/-f8Ky_WO2HTs/AAAAAAAAAAI/AAAAAAAAAG8/Q5eXh5dH1rg/s50-c-k-no/photo.jpg",
            "userId": "108962687437084869445"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np; np.random.seed(1)\n",
        "\n",
        "pruning_percentages = [\n",
        "    0., .75, .85, .9, .95, .975, .99, 1.]\n",
        "pruning_accys = []\n",
        "\n",
        "# using a pre-trained model, uncomment this\n",
        "# train_loss = 0.\n",
        "# train_set = ay.utils.generate_dataset((x_train, y_train), batch_size)\n",
        "# train_msg = 'Epoch {} mean train loss = {:.4f}'\n",
        "# train_range = trange(\n",
        "#     train_size // batch_size, \n",
        "#     desc=train_msg.format(epoch, train_loss),\n",
        "#     file=sys.stdout)\n",
        "# for _ in train_range:\n",
        "#   x, y = next(train_set)\n",
        "#   train_loss, _ = sess.run((loss_op, train_op), feed_dict={\n",
        "#       inputs_ph: x,\n",
        "#       labels_ph: y, \n",
        "#       sampling_mode_ph: bbb.EstimatorModes.sample,\n",
        "#   })\n",
        "#   train_range.set_description(train_msg.format(epoch, train_loss))\n",
        "\n",
        "for percentage in pruning_percentages:\n",
        "  sess.run(\n",
        "      assign_pruned_vars_op, feed_dict={\n",
        "          percentage_ph: percentage,\n",
        "          sampling_mode_ph: bbb.EstimatorModes.mean,\n",
        "      })\n",
        "  test_accy = 0.\n",
        "  test_set = ay.utils.generate_dataset((x_test, y_test), batch_size)\n",
        "  for test_steps_taken in range(test_size // batch_size):\n",
        "    x, y = next(test_set)\n",
        "    test_accy += sess.run(template_accy_op, feed_dict={\n",
        "        inputs_ph: x,\n",
        "        labels_ph: y,\n",
        "    })\n",
        "  \n",
        "  print()\n",
        "  sparse_variables = sess.run(template_variables)\n",
        "  for sparse, tfsparse in zip(sparse_variables, template_variables):\n",
        "    nnz = np.count_nonzero(sparse)\n",
        "    n = ay.utils.product(sparse.shape)\n",
        "    print(\"{}: total nonzero {:d}/{:d} = {:.2f}%\".format(\n",
        "        tfsparse.name, int(nnz), int(n), nnz / n * 100.))\n",
        "\n",
        "  pruning_accy = 100. * (test_accy / (test_steps_taken + 1))\n",
        "  pruning_accys.append(pruning_accy)\n",
        "  print('Epoch {} accy of pruning {:.2f}% = {:.2f}%'.format(\n",
        "      epoch, 100. * percentage, pruning_accy))\n",
        "  print()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "template/conv2d/kernel:0: total nonzero 288/288 = 100.00%\n",
            "template/conv2d/bias:0: total nonzero 32/32 = 100.00%\n",
            "template/conv2d_1/kernel:0: total nonzero 18432/18432 = 100.00%\n",
            "template/conv2d_1/bias:0: total nonzero 64/64 = 100.00%\n",
            "template/dense/kernel:0: total nonzero 4718592/4718592 = 100.00%\n",
            "template/dense/bias:0: total nonzero 128/128 = 100.00%\n",
            "template/dense_1/kernel:0: total nonzero 1280/1280 = 100.00%\n",
            "template/dense_1/bias:0: total nonzero 10/10 = 100.00%\n",
            "Epoch 0 accy of pruning 0.00% = 89.22%\n",
            "\n",
            "\n",
            "template/conv2d/kernel:0: total nonzero 284/288 = 98.61%\n",
            "template/conv2d/bias:0: total nonzero 30/32 = 93.75%\n",
            "template/conv2d_1/kernel:0: total nonzero 17794/18432 = 96.54%\n",
            "template/conv2d_1/bias:0: total nonzero 14/64 = 21.88%\n",
            "template/dense/kernel:0: total nonzero 1165290/4718592 = 24.70%\n",
            "template/dense/bias:0: total nonzero 29/128 = 22.66%\n",
            "template/dense_1/kernel:0: total nonzero 1261/1280 = 98.52%\n",
            "template/dense_1/bias:0: total nonzero 5/10 = 50.00%\n",
            "Epoch 0 accy of pruning 75.00% = 89.47%\n",
            "\n",
            "\n",
            "template/conv2d/kernel:0: total nonzero 284/288 = 98.61%\n",
            "template/conv2d/bias:0: total nonzero 30/32 = 93.75%\n",
            "template/conv2d_1/kernel:0: total nonzero 17639/18432 = 95.70%\n",
            "template/conv2d_1/bias:0: total nonzero 7/64 = 10.94%\n",
            "template/dense/kernel:0: total nonzero 691591/4718592 = 14.66%\n",
            "template/dense/bias:0: total nonzero 15/128 = 11.72%\n",
            "template/dense_1/kernel:0: total nonzero 1256/1280 = 98.12%\n",
            "template/dense_1/bias:0: total nonzero 2/10 = 20.00%\n",
            "Epoch 0 accy of pruning 85.00% = 89.43%\n",
            "\n",
            "\n",
            "template/conv2d/kernel:0: total nonzero 284/288 = 98.61%\n",
            "template/conv2d/bias:0: total nonzero 30/32 = 93.75%\n",
            "template/conv2d_1/kernel:0: total nonzero 17500/18432 = 94.94%\n",
            "template/conv2d_1/bias:0: total nonzero 6/64 = 9.38%\n",
            "template/dense/kernel:0: total nonzero 454796/4718592 = 9.64%\n",
            "template/dense/bias:0: total nonzero 12/128 = 9.38%\n",
            "template/dense_1/kernel:0: total nonzero 1253/1280 = 97.89%\n",
            "template/dense_1/bias:0: total nonzero 2/10 = 20.00%\n",
            "Epoch 0 accy of pruning 90.00% = 89.56%\n",
            "\n",
            "\n",
            "template/conv2d/kernel:0: total nonzero 282/288 = 97.92%\n",
            "template/conv2d/bias:0: total nonzero 28/32 = 87.50%\n",
            "template/conv2d_1/kernel:0: total nonzero 17284/18432 = 93.77%\n",
            "template/conv2d_1/bias:0: total nonzero 5/64 = 7.81%\n",
            "template/dense/kernel:0: total nonzero 218087/4718592 = 4.62%\n",
            "template/dense/bias:0: total nonzero 5/128 = 3.91%\n",
            "template/dense_1/kernel:0: total nonzero 1249/1280 = 97.58%\n",
            "template/dense_1/bias:0: total nonzero 2/10 = 20.00%\n",
            "Epoch 0 accy of pruning 95.00% = 89.82%\n",
            "\n",
            "\n",
            "template/conv2d/kernel:0: total nonzero 280/288 = 97.22%\n",
            "template/conv2d/bias:0: total nonzero 28/32 = 87.50%\n",
            "template/conv2d_1/kernel:0: total nonzero 17095/18432 = 92.75%\n",
            "template/conv2d_1/bias:0: total nonzero 2/64 = 3.12%\n",
            "template/dense/kernel:0: total nonzero 99821/4718592 = 2.12%\n",
            "template/dense/bias:0: total nonzero 1/128 = 0.78%\n",
            "template/dense_1/kernel:0: total nonzero 1243/1280 = 97.11%\n",
            "template/dense_1/bias:0: total nonzero 1/10 = 10.00%\n",
            "Epoch 0 accy of pruning 97.50% = 89.72%\n",
            "\n",
            "\n",
            "template/conv2d/kernel:0: total nonzero 277/288 = 96.18%\n",
            "template/conv2d/bias:0: total nonzero 27/32 = 84.38%\n",
            "template/conv2d_1/kernel:0: total nonzero 16749/18432 = 90.87%\n",
            "template/conv2d_1/bias:0: total nonzero 0/64 = 0.00%\n",
            "template/dense/kernel:0: total nonzero 29100/4718592 = 0.62%\n",
            "template/dense/bias:0: total nonzero 0/128 = 0.00%\n",
            "template/dense_1/kernel:0: total nonzero 1234/1280 = 96.41%\n",
            "template/dense_1/bias:0: total nonzero 1/10 = 10.00%\n",
            "Epoch 0 accy of pruning 99.00% = 89.28%\n",
            "\n",
            "\n",
            "template/conv2d/kernel:0: total nonzero 0/288 = 0.00%\n",
            "template/conv2d/bias:0: total nonzero 0/32 = 0.00%\n",
            "template/conv2d_1/kernel:0: total nonzero 0/18432 = 0.00%\n",
            "template/conv2d_1/bias:0: total nonzero 0/64 = 0.00%\n",
            "template/dense/kernel:0: total nonzero 0/4718592 = 0.00%\n",
            "template/dense/bias:0: total nonzero 0/128 = 0.00%\n",
            "template/dense_1/kernel:0: total nonzero 0/1280 = 0.00%\n",
            "template/dense_1/bias:0: total nonzero 0/10 = 0.00%\n",
            "Epoch 0 accy of pruning 100.00% = 9.81%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cZiGcINFIoEN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pruning visualization"
      ]
    },
    {
      "metadata": {
        "id": "jygoumjOk_sM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "33eb86e3-d71d-4e40-f7f1-8d023948030c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524669862723,
          "user_tz": 240,
          "elapsed": 525,
          "user": {
            "displayName": "Sam Wenke",
            "photoUrl": "//lh6.googleusercontent.com/-f8Ky_WO2HTs/AAAAAAAAAAI/AAAAAAAAAG8/Q5eXh5dH1rg/s50-c-k-no/photo.jpg",
            "userId": "108962687437084869445"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.ylabel('% Accuracy')\n",
        "plt.xlabel('% Pruned')\n",
        "plt.ylim([0, 100.])\n",
        "_ = plt.plot(\n",
        "    np.asarray(pruning_percentages[1:]) * 100., pruning_accys[1:], marker='o')\n",
        "_ = plt.axhline(y=pruning_accys[0], color='r', linestyle='-')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFcCAYAAAAzhzxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMBgFHIAAAxGIQcAwGD/H2yBFs8Xudc4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f71a9d55a20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "0rWB6TePHhAM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# BONUS: Train after pruning"
      ]
    },
    {
      "metadata": {
        "id": "OCZudVEYvP42",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "template_optimizer = ay.contrib.train.SparseVariableOptimizer(\n",
        "    tf.train.AdamOptimizer(1e-3))\n",
        "grads_and_vars = template_optimizer.compute_gradients(\n",
        "    template_loss_op, template_variables)\n",
        "template_train_op = template_optimizer.apply_gradients(grads_and_vars)\n",
        "template_optimizer_init_op = template_optimizer.get_initializer(\n",
        "    template_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQbwnDgEvYT7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "027e0770-86fc-4b72-e456-cee0c2cc2498",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524669884620,
          "user_tz": 240,
          "elapsed": 21102,
          "user": {
            "displayName": "Sam Wenke",
            "photoUrl": "//lh6.googleusercontent.com/-f8Ky_WO2HTs/AAAAAAAAAAI/AAAAAAAAAG8/Q5eXh5dH1rg/s50-c-k-no/photo.jpg",
            "userId": "108962687437084869445"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess.run(\n",
        "    assign_pruned_vars_op, feed_dict={\n",
        "        percentage_ph: .99,\n",
        "        sampling_mode_ph: bbb.EstimatorModes.mean,\n",
        "    })\n",
        "\n",
        "num_re_epochs = 1\n",
        "sess.run(template_optimizer_init_op)\n",
        "for epoch in range(num_re_epochs):\n",
        "  train_loss = 0.\n",
        "  train_set = ay.utils.generate_dataset((x_train, y_train), batch_size)\n",
        "  train_msg = 'Epoch {} mean train loss = {:.4f}'\n",
        "  train_range = trange(\n",
        "      train_size // batch_size, \n",
        "      desc=train_msg.format(epoch, train_loss),\n",
        "      file=sys.stdout)\n",
        "  for _ in train_range:\n",
        "    x, y = next(train_set)\n",
        "    train_loss, _ = sess.run((template_loss_op, template_train_op), feed_dict={\n",
        "        inputs_ph: x,\n",
        "        labels_ph: y, \n",
        "    })\n",
        "    train_range.set_description(train_msg.format(epoch, train_loss))\n",
        "\n",
        "  test_accy = 0.\n",
        "  test_set = ay.utils.generate_dataset((x_test, y_test), batch_size)\n",
        "  for test_steps_taken in range(test_size // batch_size):\n",
        "    x, y = next(test_set)\n",
        "    test_accy_ = sess.run(template_accy_op, feed_dict={\n",
        "        inputs_ph: x,\n",
        "        labels_ph: y,\n",
        "    })\n",
        "    test_accy += test_accy_\n",
        "  print('Accy {:.2f}%'.format(100. * (test_accy / (test_steps_taken + 1))))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 mean train loss = 0.3868: 100%|██████████| 937/937 [00:19<00:00, 48.49it/s]\n",
            "Accy 97.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7pwV95ukHyFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Benchmark the inferencing time, just for kicks"
      ]
    },
    {
      "metadata": {
        "id": "_rnakxS0C4nD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2b9e4873-2bac-42fd-8f5d-f11df0e1cb64",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524669901709,
          "user_tz": 240,
          "elapsed": 17059,
          "user": {
            "displayName": "Sam Wenke",
            "photoUrl": "//lh6.googleusercontent.com/-f8Ky_WO2HTs/AAAAAAAAAAI/AAAAAAAAAG8/Q5eXh5dH1rg/s50-c-k-no/photo.jpg",
            "userId": "108962687437084869445"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "times = []\n",
        "test_accy = 0.\n",
        "test_set = ay.utils.generate_dataset((x_test, y_test), 1)\n",
        "for test_steps_taken in range(test_size // 1):\n",
        "  x, y = next(test_set)\n",
        "  start = time.time()\n",
        "  sess.run(template_logits, feed_dict={\n",
        "      inputs_ph: x,\n",
        "  })\n",
        "  end = time.time() - start\n",
        "  times.append(end)\n",
        "times = np.array(times)\n",
        "\n",
        "print('mean time = {:.5f} ms'.format(times.mean()))\n",
        "print('stdv time = {:.5f} ms'.format(times.std()))\n",
        "print('max time = {:.5f} ms'.format(times.max()))\n",
        "print('min time = {:.5f} ms'.format(times.min()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean time = 0.00165 ms\n",
            "stdv time = 0.00055 ms\n",
            "max time = 0.05416 ms\n",
            "min time = 0.00130 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "86ICq9fwNvHC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By exploiting these zero entries, you can often reduce the storage and computational requirements to O(tau*n) and O(tau*n²) respectively, where tau is the average number of entries in each column. This reduction makes the solution of large problems (n in the millions or larger) tractable on most computers."
      ]
    },
    {
      "metadata": {
        "id": "HJ3yv5veNt4l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f375f304-0ec9-40d5-f216-3f5c425b70a0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524669902048,
          "user_tz": 240,
          "elapsed": 292,
          "user": {
            "displayName": "Sam Wenke",
            "photoUrl": "//lh6.googleusercontent.com/-f8Ky_WO2HTs/AAAAAAAAAAI/AAAAAAAAAG8/Q5eXh5dH1rg/s50-c-k-no/photo.jpg",
            "userId": "108962687437084869445"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sparse_variables = sess.run(template_variables)\n",
        "for sparse, tfsparse in zip(sparse_variables, template_variables):\n",
        "  nnz = np.count_nonzero(sparse)\n",
        "  n = ay.utils.product(sparse.shape)\n",
        "  print(\"{}: total nonzero {:d}/{:d} = {:.2f}%\".format(\n",
        "      tfsparse.name, int(nnz), int(n), nnz / n * 100.))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "template/conv2d/kernel:0: total nonzero 277/288 = 96.18%\n",
            "template/conv2d/bias:0: total nonzero 27/32 = 84.38%\n",
            "template/conv2d_1/kernel:0: total nonzero 16749/18432 = 90.87%\n",
            "template/conv2d_1/bias:0: total nonzero 0/64 = 0.00%\n",
            "template/dense/kernel:0: total nonzero 29100/4718592 = 0.62%\n",
            "template/dense/bias:0: total nonzero 0/128 = 0.00%\n",
            "template/dense_1/kernel:0: total nonzero 1234/1280 = 96.41%\n",
            "template/dense_1/bias:0: total nonzero 1/10 = 10.00%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}